import numpy as np
import pandas as pd
from scipy import stats
import os
from sklearn.linear_model import BayesianRidge
from sklearn.impute import SimpleImputer
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
from sklearn.impute import KNNImputer
# from miracle import *
# from pypots.imputation import SAITS,TimeMixerPP,TimeLLM,MOMENT,TEFN
from typing import Optional
# from pypots.optim.adam import Adam
# from pypots.nn.modules.loss import MAE, MSE
import torch
from torch.utils.data import Dataset, DataLoader
from models_impute import *

def zero_impu(mx):
   return np.nan_to_num(mx, nan=0)
# åœ¨baseline.pyä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
# def zero_impu(mx):
#     print(f"ğŸ” zero_impu è¾“å…¥: ç¼ºå¤±å€¼æ•°é‡ = {np.isnan(mx).sum()}")
#     result = mx.copy()
    
#     # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†é¢„å¤„ç†
#     if hasattr(zero_impu, '_debug'):
#         print("zero_impu: ç›´æ¥ç”¨0å¡«å……")
#         result[np.isnan(result)] = 0.0
#     else:
#         # å¯èƒ½è¿™é‡Œè°ƒç”¨äº†å…¶ä»–å¤„ç†å‡½æ•°
#         result = FirstProcess(result)  # â† è¿™é‡Œå¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨
#         result = SecondProcess(result)
    
#     print(f"ğŸ” zero_impu è¾“å‡º: ç¼ºå¤±å€¼æ•°é‡ = {np.isnan(result).sum()}")
#     print(f"ğŸ” zero_impu è¾“å‡º: é›¶å€¼æ•°é‡ = {(result == 0).sum()}")
#     return result
def mean_impu(mx):
    # mx = mx.copy()
    # col_means = np.nanmean(mx, axis=0)
    # inds = np.where(np.isnan(mx))
    # mx[inds] = np.take(col_means, inds[1])
    # if np.isnan(mx).any():
    #     mx = np.nan_to_num(mx, nan=-1)
    # return mx
    mean = np.nanmean(mx)
    return np.where(np.isnan(mx), mean, mx)

def median_impu(mx):
    mx = mx.copy()
    # col_medians = np.nanmedian(mx, axis=0)
    # inds = np.where(np.isnan(mx))
    # mx[inds] = np.take(col_medians, inds[1])
    # if np.isnan(mx).any():
    #     mx = np.nan_to_num(mx, nan=-1)
    # return mx
    median = np.nanmedian(mx)
    return np.where(np.isnan(mx), median, mx)

def mode_impu(mx):
    mx = mx.copy()
    flat_values = mx[~np.isnan(mx)]  # å±•å¹³æ‰€æœ‰éNaNå€¼
    global_mode = stats.mode(flat_values, keepdims=False).mode
    if np.isnan(global_mode):
        global_mode = 0  # å…œåº•
    inds = np.where(np.isnan(mx))
    mx[inds] = global_mode
    return mx

def random_impu(mx):
    mx = mx.copy()
    non_nan_values = mx[~np.isnan(mx)]  # è·å–æ‰€æœ‰éç¼ºå¤±å€¼ï¼ˆ1Dæ•°ç»„ï¼‰
    
    if non_nan_values.size == 0:
        # æ•´å¼ è¡¨å…¨æ˜¯ NaNï¼Œå…œåº•å¡« -1
        mx[:] = -1
        return mx

    inds = np.where(np.isnan(mx))  # æ‰¾åˆ°æ‰€æœ‰ NaN çš„ä½ç½®
    mx[inds] = np.random.choice(non_nan_values, size=len(inds[0]), replace=True)
    return mx


# def knn_impu(mx, k=5):
#     mx = mx.copy()
#     all_nan_cols = np.all(np.isnan(mx), axis=0)

#     # è®¡ç®—å…¨å±€å‡å€¼ï¼ˆä¸ä¸º NaNï¼‰
#     global_mean = np.nanmean(mx)

#     # å…¨ç©ºåˆ—å…ˆå¡«å…¨å±€å‡å€¼ï¼Œé¿å… KNNImputer æŠ¥é”™
#     mx[:, all_nan_cols] = global_mean

#     imputer = KNNImputer(n_neighbors=k)
#     return imputer.fit_transform(mx)

def knn_impu(mx, k=5):
    import time
    start_time = time.time()
    
    print(f"ğŸ” å¼€å§‹KNNå¡«è¡¥: æ•°æ®å½¢çŠ¶={mx.shape}, ç¼ºå¤±å€¼={np.isnan(mx).sum()}")
    
    mx = mx.copy()
    
    # âœ… 1. è®¾ç½®å•çº¿ç¨‹
    import os
    print("âš™ï¸ è®¾ç½®å•çº¿ç¨‹æ¨¡å¼...")
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'
    os.environ['OPENBLAS_NUM_THREADS'] = '1'
    
    # âœ… 2. å¤„ç†å…¨ç©ºåˆ—
    print("ğŸ”§ æ£€æŸ¥å…¨ç©ºåˆ—...")
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        print(f"   å‘ç° {all_nan_cols.sum()} ä¸ªå…¨ç©ºåˆ—ï¼Œç”¨å…¨å±€å‡å€¼å¡«å……")
        global_mean = np.nanmean(mx)
        if np.isnan(global_mean):
            global_mean = 0.0
        mx[:, all_nan_cols] = global_mean
    else:
        print("   æ— å…¨ç©ºåˆ—")
    
    # âœ… 3. è°ƒæ•´kå€¼
    print("ğŸ“Š è°ƒæ•´KNNå‚æ•°...")
    valid_samples = (~np.isnan(mx)).sum(axis=0).min()
    original_k = k
    k = min(k, max(1, valid_samples - 1))
    print(f"   kå€¼: {original_k} -> {k}")
    
    # âœ… 4. å¼€å§‹KNNå¡«è¡¥
    print("ğŸš€ å¼€å§‹KNNè®¡ç®—...")
    try:
        from sklearn.impute import KNNImputer
        imputer = KNNImputer(n_neighbors=k)
        
        print("   åˆ›å»ºKNNImputerå®Œæˆ")
        print("   å¼€å§‹fit_transform...")
        
        result = imputer.fit_transform(mx)
        
        elapsed = time.time() - start_time
        print(f"âœ… KNNå¡«è¡¥å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’")
        return result
        
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"âŒ KNNå¡«è¡¥åœ¨ {elapsed:.2f} ç§’åå¤±è´¥: {e}")
        raise e

def mice_impu(mx, max_iter=5):
    """æ”¹è¿›ï¼šå¤„ç†å…¨ç©ºåˆ— + æœ€ç®€ç‰ˆMICEå¡«è¡¥"""
    mx = mx.copy()
    n_rows, n_cols = mx.shape

    # === Step 0: å¤„ç†å…¨ç©ºåˆ— ===
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        global_mean = np.nanmean(mx)
        mx[:, all_nan_cols] = global_mean

    # === Step 1: åˆå§‹å‡å€¼å¡«è¡¥ ===
    imp = SimpleImputer(strategy='mean')
    matrix_filled = imp.fit_transform(mx)

    # === Step 2: MICEä¸»å¾ªç¯ ===
    for _ in range(max_iter): 
        for col in range(n_cols): 
            missing_idx = np.where(np.isnan(mx[:, col]))[0]
            if len(missing_idx) == 0:
                continue

            observed_idx = np.where(~np.isnan(mx[:, col]))[0]
            X_train = np.delete(matrix_filled[observed_idx], col, axis=1)
            y_train = mx[observed_idx, col]
            X_pred = np.delete(matrix_filled[missing_idx], col, axis=1)

            model = BayesianRidge()
            model.fit(X_train, y_train)
            matrix_filled[missing_idx, col] = model.predict(X_pred)

    return matrix_filled

def ffill_impu(mx):
    mx = mx.copy()
    df = pd.DataFrame(mx)
    df = df.ffill(axis=0)

    # è¡¥å…¨å‰å‡ è¡Œæœªè¢«å¡«è¡¥çš„ä½ç½®ï¼ˆä¾‹å¦‚ç¬¬ä¸€è¡Œæ˜¯ NaNï¼‰
    global_mean = np.nanmean(mx)
    df = df.fillna(global_mean)

    return df.values

def bfill_impu(mx):
    mx = mx.copy()
    df = pd.DataFrame(mx)
    df = df.bfill(axis=0)

    # è¡¥å…¨æœ€åå‡ è¡Œæœªè¢«å¡«è¡¥çš„ä½ç½®ï¼ˆä¾‹å¦‚æœ€åä¸€è¡Œæ˜¯ NaNï¼‰
    global_mean = np.nanmean(mx)
    df = df.fillna(global_mean)

    return df.values

def miracle_impu(mx: np.ndarray) -> np.ndarray:
    from miracle import MIRACLE
    mx = mx.copy().astype(np.float32)
    global_mean = np.nanmean(mx)
    if np.isnan(global_mean):
        global_mean = 0.0
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        mx[:, all_nan_cols] = global_mean

    n_feats = mx.shape[1]
    missing_idx = np.where(np.any(np.isnan(mx), axis=0))[0][:20]

    model = MIRACLE(
        num_inputs=n_feats,
        missing_list=missing_idx.tolist(),
        n_hidden=min(32, max(8, n_feats // 2)),
        lr=0.008,
        max_steps=50,
        window=5,
        seed=42
    )

    result = model.fit(mx)

    del model
    gc.collect()
    return result.astype(np.float32)


# âœ… åŒæ—¶ä¼˜åŒ–å…¶ä»–æ–¹æ³•ï¼Œæé«˜æ•´ä½“baselineè´¨é‡
def saits_impu(mx, epochs=None, d_model=None, n_layers=None, device=None):
    """åŠ¨æ€å‚æ•°çš„SAITSå¡«è¡¥"""
    from pypots.imputation import SAITS
    
    mx = mx.copy()
    seq_len, n_features = mx.shape
    total_size = seq_len * n_features
    
    # å¤„ç†å…¨ç©ºåˆ—
    global_mean = np.nanmean(mx)
    if np.isnan(global_mean):
        global_mean = 0.0
    
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        mx[:, all_nan_cols] = global_mean
    
    # âœ… æ ¹æ®æ•°æ®å¤§å°åŠ¨æ€è°ƒæ•´å‚æ•°
    if epochs is None:
        if total_size > 50000:
            epochs = 20
            d_model = 64
            n_layers = 1
        elif total_size > 10000:
            epochs = 50
            d_model = 128
            n_layers = 2
        else:
            epochs = 100
            d_model = 128
            n_layers = 2
    
    if d_model is None:
        d_model = min(128, max(32, n_features * 4))
    
    if n_layers is None:
        n_layers = 2 if total_size < 20000 else 1
    
    try:
        data_3d = mx[np.newaxis, :, :]
        
        saits = SAITS(
            n_steps=seq_len,
            n_features=n_features,
            n_layers=n_layers,
            d_model=d_model,
            n_heads=min(4, d_model // 32),
            d_k=d_model // 8,
            d_v=d_model // 8,
            d_ffn=d_model,
            dropout=0.1,
            epochs=epochs,
            patience=10,
            batch_size=32,
            device=device or ('cuda' if torch.cuda.is_available() else 'cpu'),
        )
        
        train_set = {"X": data_3d}
        saits.fit(train_set)
        imputed_data_3d = saits.impute(train_set)
        
        return imputed_data_3d[0]
        
    except Exception as e:
        print(f"SAITSå¤±è´¥: {e}")
        return mean_impu(mx)


def timemixerpp_impu(mx):
    import numpy as np
    import torch
    from pypots.imputation import TimeMixerPP
    from sklearn.impute import SimpleImputer

    # Step 1: å‡†å¤‡è¾“å…¥æ•°æ® (T, N) â†’ (1, T, N)
    mx = mx.astype(np.float32)
    global_mean = np.nanmean(mx)
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        print(f"å‘ç° {all_nan_cols.sum()} åˆ—å…¨ä¸ºNaNï¼Œè¿™äº›åˆ—å°†ç”¨å¡«å……")
        mx[:, all_nan_cols] = global_mean
    T, N = mx.shape
    data = mx[None, ...]  # (1, T, N)

    # Step 2: æ„å»º mask
    missing_mask = np.isnan(data).astype(np.float32)
    indicating_mask = (~np.isnan(data)).astype(np.float32)

    # Step 3: ç®€å•å‡å€¼å¡«è¡¥åˆå§‹ç¼ºå¤±å€¼
    imp = SimpleImputer(strategy='mean', keep_empty_features=True)
    X_filled = imp.fit_transform(mx).astype(np.float32)
    X_filled = X_filled[None, ...]

    # Step 4: æ„é€ æ•°æ®å­—å…¸
    dataset = {
        "X": X_filled,
        "missing_mask": missing_mask,
        "indicating_mask": indicating_mask,
        "X_ori": data
    }

    # Step 5: åˆå§‹åŒ–æ¨¡å‹
    model = TimeMixerPP(
            n_steps=T,
            n_features=N,
            n_layers=1,
            d_model=64,  # âœ… å¢å¤§åˆ°64
            d_ffn=128,   # âœ… å¢å¤§åˆ°128
            top_k=T//2,  # âœ… åŠ¨æ€è®¾ç½®ä¸ºæ—¶é—´æ­¥çš„ä¸€åŠ
            n_heads=2,   # âœ… å¢åŠ åˆ°2
            n_kernels=6, # âœ… å¢åŠ åˆ°6ï¼Œç¡®ä¿å¤šå°ºåº¦
            dropout=0.1,
            channel_mixing=True,   # âœ… æ”¹ä¸ºTrue
            channel_independence=False,  # âœ… æ”¹ä¸ºFalse
            downsampling_layers=1,    # âœ… æ”¹ä¸º1å±‚ä¸‹é‡‡æ ·
            downsampling_window=2,    # âœ… æ”¹ä¸º2
            apply_nonstationary_norm=False,
            batch_size=1,
            epochs=10,
            patience=3,
            verbose=False,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )

    # Step 6: è®­ç»ƒæ¨¡å‹
    model.fit(train_set=dataset)

    # Step 7: ä½¿ç”¨æ ‡å‡†é¢„æµ‹æ–¹æ³•
    result = model.predict(dataset)
    if isinstance(result, dict):
        imputed = result.get('imputation', list(result.values())[0])
    else:
        imputed = result

    # ç§»é™¤batchç»´åº¦
    if len(imputed.shape) == 3:
        imputed = imputed[0]  # (T, N)

    return imputed


def tefn_impu(mx, epoch=100, device=None):
    from pypots.imputation import TEFN
    from pypots.optim.adam import Adam
    from pypots.nn.modules.loss import MAE, MSE
    global_mean = np.nanmean(mx)
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    if all_nan_cols.any():
        print(f"å‘ç° {all_nan_cols.sum()} åˆ—å…¨ä¸ºNaNï¼Œè¿™äº›åˆ—å°†ç”¨å¡«å……")
        mx[:, all_nan_cols] = global_mean
    mx = mx.copy()
    n_steps, n_features = mx.shape

    data = mx[np.newaxis, :, :]  # shape: (1, T, F)
    missing_mask = (~np.isnan(data)).astype(np.float32)
    indicating_mask = 1 - missing_mask
    data_filled = np.nan_to_num(data, nan=0.0).astype(np.float32)
    X_ori_no_nan = np.nan_to_num(data, nan=0.0).astype(np.float32)
    class OneSampleDataset(Dataset):
        def __len__(self): return 1
        def __getitem__(self, idx):
            return (
                idx,
                data_filled[0],
                missing_mask[0],
                X_ori_no_nan[0],
                indicating_mask[0],
            )

    dataloader = DataLoader(OneSampleDataset(), batch_size=1, shuffle=False)

    model = TEFN(
        n_steps=n_steps,
        n_features=n_features,
        n_fod=2,
        apply_nonstationary_norm=True,
        ORT_weight=1.0,
        MIT_weight=1.0,
        batch_size=1,
        epochs=epoch,
        patience=5,
        training_loss=MAE,
        validation_metric=MSE,
        optimizer=Adam,
        device=device,
        saving_path=None,
        model_saving_strategy=None,
        verbose=False,
    )
    model._train_model(dataloader, dataloader)
    model.model.load_state_dict(model.best_model_dict)

    # æ„é€ æ¨ç†æ•°æ®
    X = torch.tensor(data_filled, dtype=torch.float32).to(model.device)
    missing_mask = torch.tensor(missing_mask, dtype=torch.float32).to(model.device)

    # æ¨ç†å¡«è¡¥
    model.model.eval()
    with torch.no_grad():
        output = model.model({
            'X': X,
            'missing_mask': missing_mask,
        })
        imputed = output['imputation']

    # æ›¿æ¢ç¼ºå¤±ä½ç½®
    X_ori_tensor = torch.tensor(X_ori_no_nan, dtype=torch.float32).to(model.device)
    result = X_ori_tensor.clone()
    result[missing_mask == 0] = imputed[missing_mask == 0]

    return result.cpu().numpy().squeeze()
def timesnet_impu(mx):
    import numpy as np
    from pypots.imputation.timesnet import TimesNet  # æ ¹æ®å®é™…é¡¹ç›®ç»“æ„è°ƒæ•´

    # å¤åˆ¶åŸå§‹æ•°æ®
    mx = mx.copy()
    n_steps, n_features = mx.shape

    # è®°å½•å…¨ç©ºåˆ—
    all_nan_cols = np.all(np.isnan(mx), axis=0)

    # è®¡ç®—å…¨å±€å‡å€¼ç”¨äºå¡«è¡¥å…¨ç©ºåˆ—
    non_nan_values = mx[~np.isnan(mx)]
    global_mean = np.mean(non_nan_values) if non_nan_values.size > 0 else 0.0

    # ç”¨å…¨å±€å‡å€¼å¡«è¡¥å…¨ç©ºåˆ—ï¼ˆå®Œå…¨ NaN çš„åˆ—ï¼‰
    for i in range(n_features):
        if all_nan_cols[i]:
            mx[:, i] = global_mean

    # æ„é€ ç¼ºå¤±æ©ç ï¼ˆæ³¨æ„æ­¤æ—¶å·²ç»æ²¡æœ‰å…¨ç©ºåˆ—ï¼‰
    mask = ~np.isnan(mx)
    mx_filled = np.nan_to_num(mx, nan=0.0)  # å…¶ä½™ NaN å¡« 0ï¼Œç”¨ä½œæ¨¡å‹è¾“å…¥

    # åˆå§‹åŒ– TimesNet æ¨¡å‹
    model = TimesNet(
        n_steps=n_steps,
        n_features=n_features,
        n_layers=2,
        top_k=1,
        d_model=2,
        d_ffn=2,
        n_kernels=2,
        dropout=0.1,
        batch_size=1,
        epochs=5,
        patience=5,
        device="cuda" if torch.cuda.is_available() else "cpu",
        verbose=False,
    )

    # æ„é€ è¾“å…¥æ•°æ®
    data = {
        "X": mx_filled[None, ...],            # (1, T, N)
        "missing_mask": mask[None, ...],      # (1, T, N)
        "X_ori": mx[None, ...],               # åŸå§‹å¸¦ç¼ºå¤±å€¼
        "indicating_mask": mask[None, ...],   # ä¸ missing_mask ç›¸åŒ
    }

    # æ‹Ÿåˆæ¨¡å‹
    model.fit(data)

    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œå¡«è¡¥
    imputed = model.predict({"X": mx_filled[None, ...], "missing_mask": mask[None, ...]})
    return imputed["imputation"][0]  # è¿”å›å¡«è¡¥åçš„ (T, N) çŸ©é˜µ

def tsde_impu(mx, n_samples: int = 40, device: str = "cuda" if torch.cuda.is_available() else "cpu") -> np.ndarray:
    from tsde import impute_missing_data
    mx = mx.copy()
    mx = impute_missing_data(
            mx, 
            n_samples=n_samples, 
            device=device
        )
    return mx

def grin_impu(mx):
    """GRINå¡«è¡¥æ–¹æ³• - ä½å†…å­˜ç‰ˆæœ¬"""
    from grin import grin_impute_low_memory
    try:
        mx = mx.copy()
        seq_len, n_features = mx.shape
        
        print(f"åŸå§‹ç¼ºå¤±å€¼: {np.isnan(mx).sum()}")
        
        # âœ… æ”¾å®½é™åˆ¶æ¡ä»¶ï¼Œä½†ä¿æŒä½å†…å­˜
        if seq_len < 10:
            print("âš ï¸ åºåˆ—å¤ªçŸ­ï¼Œä½¿ç”¨å‡å€¼å¡«è¡¥")
            return mean_impu(mx)
        
        # æ ¹æ®æ•°æ®å¤§å°è°ƒæ•´å‚æ•°
        total_size = seq_len * n_features
        
        if total_size > 50000:  # å¤§æ•°æ®é›†
            window_size = min(10, seq_len // 10)
            hidden_dim = min(8, max(4, n_features // 10))
            epochs = 80
            print(f"ğŸ”§ å¤§æ•°æ®é›†æ¨¡å¼: window={window_size}, hidden={hidden_dim}")
        elif total_size > 10000:  # ä¸­ç­‰æ•°æ®é›†
            window_size = min(15, seq_len // 8) 
            hidden_dim = min(16, max(8, n_features // 8))
            epochs = 100
            print(f"ğŸ”§ ä¸­ç­‰æ•°æ®é›†æ¨¡å¼: window={window_size}, hidden={hidden_dim}")
        else:  # å°æ•°æ®é›†
            window_size = min(20, seq_len // 4)
            hidden_dim = min(32, max(16, n_features // 4))
            epochs = 120
            print(f"ğŸ”§ å°æ•°æ®é›†æ¨¡å¼: window={window_size}, hidden={hidden_dim}")
        
        # è°ƒç”¨ä½å†…å­˜ç‰ˆGRIN
        from grin import grin_impute_low_memory
        result = grin_impute_low_memory(
            mx, 
            window_size=window_size,
            hidden_dim=hidden_dim,
            epochs=epochs,
            lr=0.01
        )
        
        # éªŒè¯å¡«è¡¥ç»“æœ
        if np.isnan(result).any():
            print("ğŸ”„ GRINéƒ¨åˆ†å¡«è¡¥ï¼Œè¡¥å……å‡å€¼å¡«è¡¥")
            # åªå¯¹å‰©ä½™ç¼ºå¤±å€¼ç”¨å‡å€¼å¡«è¡¥
            remaining_nan = np.isnan(result)
            col_means = np.nanmean(mx, axis=0)
            for j in range(n_features):
                if remaining_nan[:, j].any():
                    if not np.isnan(col_means[j]):
                        result[remaining_nan[:, j], j] = col_means[j]
                    else:
                        result[remaining_nan[:, j], j] = 0
        
        return result
        
    except Exception as e:
        return mean_impu(mx)