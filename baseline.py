import numpy as np
import pandas as pd
from scipy import stats
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
from sklearn.impute import KNNImputer
# from miracle import *
# from pypots.imputation import SAITS,TimeMixerPP,TimeLLM,MOMENT,TEFN
from typing import Optional
# from pypots.optim.adam import Adam
# from pypots.nn.modules.loss import MAE, MSE
import torch
from torch.utils.data import Dataset, DataLoader
from models_impute import *

def zero_impu(mx):
   return np.nan_to_num(mx, nan=0)
# åœ¨baseline.pyä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
# def zero_impu(mx):
#     print(f"ğŸ” zero_impu è¾“å…¥: ç¼ºå¤±å€¼æ•°é‡ = {np.isnan(mx).sum()}")
#     result = mx.copy()
    
#     # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†é¢„å¤„ç†
#     if hasattr(zero_impu, '_debug'):
#         print("zero_impu: ç›´æ¥ç”¨0å¡«å……")
#         result[np.isnan(result)] = 0.0
#     else:
#         # å¯èƒ½è¿™é‡Œè°ƒç”¨äº†å…¶ä»–å¤„ç†å‡½æ•°
#         result = FirstProcess(result)  # â† è¿™é‡Œå¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨
#         result = SecondProcess(result)
    
#     print(f"ğŸ” zero_impu è¾“å‡º: ç¼ºå¤±å€¼æ•°é‡ = {np.isnan(result).sum()}")
#     print(f"ğŸ” zero_impu è¾“å‡º: é›¶å€¼æ•°é‡ = {(result == 0).sum()}")
#     return result
def mean_impu(mx):
    mx = mx.copy()
    col_means = np.nanmean(mx, axis=0)
    inds = np.where(np.isnan(mx))
    mx[inds] = np.take(col_means, inds[1])
    if np.isnan(mx).any():
        mx = np.nan_to_num(mx, nan=0)
    return mx

def median_impu(mx):
    mx = mx.copy()
    col_medians = np.nanmedian(mx, axis=0)
    inds = np.where(np.isnan(mx))
    mx[inds] = np.take(col_medians, inds[1])
    if np.isnan(mx).any():
        mx = np.nan_to_num(mx, nan=0)
    return mx

def mode_impu(mx):
    # df = pd.DataFrame(mx)
    # for column in df.columns:
    #     col_data = df[column]
    #     if col_data.isna().all():
    #         df[column] = -1
    #     else:
    #         non_nan_data = col_data.dropna()
    #         mode_value = non_nan_data.mode().iloc[0]  # æ›´ç›´æ¥å–ä¼—æ•°
    #         df[column] = col_data.fillna(mode_value)
    # return df.values
    mx = mx.copy()
    col_modes = stats.mode(mx, axis=0, nan_policy='omit').mode[0]
    inds = np.where(np.isnan(mx))
    mx[inds] = np.take(col_modes, inds[1])
    if np.isnan(mx).any():
        mx = np.nan_to_num(mx, nan=0)
    return mx

def random_impu(mx):
    # df = pd.DataFrame(mx)
    # for column in df.columns:
    #     col_data = df[column]
    #     if col_data.isna().all():
    #         df[column] = -1
    #     else:
    #         non_nan_data = col_data.dropna()
    #         if not non_nan_data.empty:
    #             random_value = np.random.choice(non_nan_data)
    #             df[column] = col_data.fillna(random_value)
    # return df.values
    mx = mx.copy()
    for col in range(mx.shape[1]):
        nan_mask = np.isnan(mx[:, col])
        non_nan = mx[~nan_mask, col]
        if non_nan.size > 0:
            mx[nan_mask, col] = np.random.choice(non_nan, size=nan_mask.sum())
        else:
            mx[nan_mask, col] = -1
    return mx

def knn_impu(mx, k=5):
    mx = mx.copy()
    imputer = KNNImputer(n_neighbors=k)
    all_nan_cols = np.all(np.isnan(mx), axis=0)
    mx[:, all_nan_cols] = -1
    return imputer.fit_transform(mx)

def ffill_impu(mx):
    mx = mx.copy()
    df = pd.DataFrame(mx)
    df = df.ffill(axis=0)  # æ²¿ç€æ—¶é—´ç»´åº¦ï¼ˆè¡Œï¼‰å‰å‘å¡«å……
    df = df.fillna(-1)     # è‹¥ç¬¬ä¸€è¡Œæ˜¯ NaN ä¼šæ®‹ç•™æœªå¡«ï¼Œè¡¥-1
    return df.values

def bfill_impu(mx):
    mx = mx.copy()
    df = pd.DataFrame(mx)
    df = df.bfill(axis=0)  # æ²¿ç€æ—¶é—´ç»´åº¦ï¼ˆè¡Œï¼‰åå‘å¡«å……
    df = df.fillna(-1)     # è‹¥æœ€åä¸€è¡Œæ˜¯ NaN ä¼šæ®‹ç•™æœªå¡«ï¼Œè¡¥-1
    return df.values

def miracle_impu(mx):
    try:
        from miracle import MIRACLE
        print("_____________1______________________")
        mx = mx.copy()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
        if not np.isnan(mx).any():
            print("æ•°æ®ä¸­æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œç›´æ¥è¿”å›åŸæ•°æ®")
            return mx
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½æ˜¯NaN
        if np.isnan(mx).all():
            print("æ‰€æœ‰å€¼éƒ½æ˜¯NaNï¼Œä½¿ç”¨0å¡«å……")
            return np.zeros_like(mx)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•´åˆ—éƒ½æ˜¯NaN
        all_nan_cols = np.all(np.isnan(mx), axis=0)
        if all_nan_cols.any():
            print(f"å‘ç° {all_nan_cols.sum()} åˆ—å…¨ä¸ºNaNï¼Œè¿™äº›åˆ—å°†ç”¨0å¡«å……")
            mx[:, all_nan_cols] = 0.0
        
        # é‡æ–°æ£€æŸ¥å‰©ä½™çš„ç¼ºå¤±å€¼
        missing_idxs = np.where(np.any(np.isnan(mx), axis=0))[0]
        
        # å¦‚æœæ²¡æœ‰å‰©ä½™çš„ç¼ºå¤±å€¼ï¼Œç›´æ¥è¿”å›
        if len(missing_idxs) == 0:
            print("å¤„ç†å®Œå…¨NaNåˆ—åï¼Œæ²¡æœ‰å‰©ä½™ç¼ºå¤±å€¼")
            return mx
        
        # å¯¹å‰©ä½™ç¼ºå¤±å€¼ä½¿ç”¨å‡å€¼å¡«å……ä½œä¸ºç§å­
        mx_imputed = mean_impu(mx)
        
        # ä½¿ç”¨MIRACLEè¿›è¡Œå¡«è¡¥
        miracle = MIRACLE(
            num_inputs=mx.shape[1],
            reg_lambda=6,
            reg_beta=4,
            n_hidden=32,
            ckpt_file="tmp.ckpt",
            missing_list=missing_idxs,
            reg_m=0.1,
            lr=0.01,
            window=10,
            max_steps=200,  # å‡å°‘è®­ç»ƒæ­¥æ•°é¿å…è¿‡æ‹Ÿåˆ
        )
        
        miracle_imputed_data_x = miracle.fit(
            mx,
            X_seed=mx_imputed,
        )
        
        # âœ… æ£€æŸ¥MIRACLEè¾“å‡ºç»“æœ
        if miracle_imputed_data_x is None:
            print("MIRACLEè¿”å›Noneï¼Œä½¿ç”¨0å¡«å……")
            return np.zeros_like(mx)
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½æ˜¯NaN
        if np.isnan(miracle_imputed_data_x).all():
            print("MIRACLEè¾“å‡ºå…¨ä¸ºNaNï¼Œä½¿ç”¨0å¡«å……")
            return np.zeros_like(mx)
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰NaNå€¼
        if np.isnan(miracle_imputed_data_x).any():
            print("MIRACLEè¾“å‡ºåŒ…å«NaNï¼Œå°†å‰©ä½™NaNæ›¿æ¢ä¸º0")
            miracle_imputed_data_x = np.where(np.isnan(miracle_imputed_data_x), 0.0, miracle_imputed_data_x)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å¤§å€¼
        if np.any(np.abs(miracle_imputed_data_x) > 1e6):
            print(f"MIRACLEè¾“å‡ºåŒ…å«å¼‚å¸¸å¤§å€¼ (max: {np.max(np.abs(miracle_imputed_data_x)):.2e})ï¼Œä½¿ç”¨å‡å€¼å¡«å……")
            return mean_impu(mx)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç©·å€¼
        if np.any(np.isinf(miracle_imputed_data_x)):
            print("MIRACLEè¾“å‡ºåŒ…å«æ— ç©·å€¼ï¼Œä½¿ç”¨å‡å€¼å¡«å……")
            return mean_impu(mx)
        
        print("MIRACLEå¡«è¡¥æˆåŠŸ")
        return miracle_imputed_data_x
        
    except Exception as e:
        print(f"MIRACLEå¡«è¡¥å¤±è´¥: {e}")
        print("ä½¿ç”¨0å¡«å……ä½œä¸ºfallback")
        mx = mx.copy()
        mx[np.isnan(mx)] = 0.0
        return mx

def saits_impu(mx, epochs=10, d_model=128, n_layers=2, n_heads=4, 
               d_k=32, d_v=32, d_ffn=64, dropout=0.4, device=None):
    from pypots.imputation import SAITS
    # print("_____________2______________________")
    mx = mx.copy()
    n_steps, n_features = mx.shape
    data_3d = mx[np.newaxis, :, :]  # shape: (1, n_steps, n_features)
    saits = SAITS(
        n_steps=n_steps,
        n_features=n_features,
        n_layers=n_layers,
        d_model=d_model,
        n_heads=n_heads,
        d_k=d_k,
        d_v=d_v,
        d_ffn=d_ffn,
        dropout=dropout,
        epochs=epochs,
        device=device,
    )
    
    train_set = {"X": data_3d}
    saits.fit(train_set)
    test_set = {"X": data_3d}
    imputed_data_3d = saits.impute(test_set)
    imputed_data_2d = imputed_data_3d[0]  # shape: (n_steps, n_features)
    return imputed_data_2d

def timemixerpp_impu(mx):
    """TimeMixer++ å¡«è¡¥å‡½æ•°çš„ä¿®å¤ç‰ˆæœ¬"""
    try:
        from pypots.imputation import TimeMixerpp
        
        # æ£€æŸ¥è¾“å…¥ç»´åº¦
        if mx.shape[1] < 5:
            print(f"TimeMixer++ éœ€è¦è‡³å°‘5ä¸ªç‰¹å¾ï¼Œå½“å‰åªæœ‰ {mx.shape[1]}ï¼Œä½¿ç”¨å‡å€¼å¡«è¡¥")
            return mean_impu(mx)
        
        # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
        if len(mx.shape) == 2:
            # æ·»åŠ batchç»´åº¦
            train_data = mx[np.newaxis, ...]
        else:
            train_data = mx
        
        # åˆ›å»ºæ¨¡å‹æ—¶æŒ‡å®šæ­£ç¡®çš„å‚æ•°
        timemixer = TimeMixerpp(
            n_steps=mx.shape[0],
            n_features=mx.shape[1],
            n_layers=16,  # å‡å°‘å±‚æ•°
            d_model=32,  # å‡å°‘æ¨¡å‹ç»´åº¦
            n_heads=4,   # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
            epochs=50,   # å‡å°‘è®­ç»ƒè½®æ•°
            batch_size=32,
            patience=1,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )
        
        # è®­ç»ƒå’Œå¡«è¡¥
        timemixer.fit(train_data)
        imputed_data = timemixer.predict(train_data)
        
        # ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®
        if len(imputed_data.shape) == 3:
            return imputed_data[0]  # ç§»é™¤batchç»´åº¦
        else:
            return imputed_data
            
    except Exception as e:
        print(f"TimeMixer++ æ‰§è¡Œå¤±è´¥: {e}")
        return mean_impu(mx)




def tefn_impu(mx, epoch=10, device=None):
    from pypots.imputation import TEFN
    from pypots.optim.adam import Adam
    from pypots.nn.modules.loss import MAE, MSE
    print("_____________4______________________")
    mx = mx.copy()
    n_steps, n_features = mx.shape

    data = mx[np.newaxis, :, :]  # shape: (1, T, F)
    missing_mask = (~np.isnan(data)).astype(np.float32)
    indicating_mask = 1 - missing_mask
    data_filled = np.nan_to_num(data, nan=0.0).astype(np.float32)
    X_ori_no_nan = np.nan_to_num(data, nan=0.0).astype(np.float32)
    class OneSampleDataset(Dataset):
        def __len__(self): return 1
        def __getitem__(self, idx):
            return (
                idx,
                data_filled[0],
                missing_mask[0],
                X_ori_no_nan[0],
                indicating_mask[0],
            )

    dataloader = DataLoader(OneSampleDataset(), batch_size=1, shuffle=False)

    model = TEFN(
        n_steps=n_steps,
        n_features=n_features,
        n_fod=2,
        apply_nonstationary_norm=True,
        ORT_weight=1.0,
        MIT_weight=1.0,
        batch_size=1,
        epochs=epoch,
        patience=5,
        training_loss=MAE,
        validation_metric=MSE,
        optimizer=Adam,
        device=device,
        saving_path=None,
        model_saving_strategy=None,
        verbose=False,
    )
    model._train_model(dataloader, dataloader)
    model.model.load_state_dict(model.best_model_dict)

    # æ„é€ æ¨ç†æ•°æ®
    X = torch.tensor(data_filled, dtype=torch.float32).to(model.device)
    missing_mask = torch.tensor(missing_mask, dtype=torch.float32).to(model.device)

    # æ¨ç†å¡«è¡¥
    model.model.eval()
    with torch.no_grad():
        output = model.model({
            'X': X,
            'missing_mask': missing_mask,
        })
        imputed = output['imputation']

    # æ›¿æ¢ç¼ºå¤±ä½ç½®
    X_ori_tensor = torch.tensor(X_ori_no_nan, dtype=torch.float32).to(model.device)
    result = X_ori_tensor.clone()
    result[missing_mask == 0] = imputed[missing_mask == 0]

    return result.cpu().numpy().squeeze()