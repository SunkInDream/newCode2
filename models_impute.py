import os
import torch
import random
import gc
import numpy as np
import pandas as pd
from tqdm import tqdm
# import tensorflow as tf
import multiprocessing as mp 
from models_TCDF import *
import torch.nn.functional as F
from pygrinder import (
    mcar,
    mar_logistic,
    mnar_x,
)

from sklearn.cluster import KMeans
from baseline import *
from multiprocessing import set_start_method
from scipy.stats import wasserstein_distance
from models_downstream import *
from multiprocessing import Process, Queue
from models_TCN import MultiADDSTCN, ParallelFeatureADDSTCN, ADDSTCN

def FirstProcess(matrix, threshold=0.8):
    matrix = np.array(matrix, dtype=np.float32)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šå¤„ç†ç©ºåˆ—å’Œé«˜é‡å¤åˆ—
    for col_idx in range(matrix.shape[1]):
        col_data = matrix[:, col_idx]
        
        if np.isnan(col_data).all():
            matrix[:, col_idx] = -1
            continue
            
        valid_mask = ~np.isnan(col_data)
        if not valid_mask.any():
            continue
            
        valid_data = col_data[valid_mask]
        unique_vals, counts = np.unique(valid_data, return_counts=True)
        max_count_idx = np.argmax(counts)
        mode_value = unique_vals[max_count_idx]
        mode_count = counts[max_count_idx]
        
        if mode_count >= threshold * len(valid_data):
            matrix[np.isnan(col_data), col_idx] = mode_value
    return matrix

def SecondProcess(matrix, perturbation_prob=0.3, perturbation_scale=0.3):
    for col_idx in range(matrix.shape[1]):
        col_data = matrix[:, col_idx]
        missing_mask = np.isnan(col_data)
        
        if not missing_mask.any():
            continue
        
        series = pd.Series(col_data)
        interpolated = series.interpolate(method='linear', limit_direction='both').values
        
        if np.isnan(interpolated).any():
            interpolated[np.isnan(interpolated)] = np.nanmean(col_data)
        
        # æ·»åŠ æ‰°åŠ¨
        missing_indices = np.where(missing_mask)[0]
        if len(missing_indices) > 0 and perturbation_prob > 0:
            n_perturb = int(len(missing_indices) * perturbation_prob)
            if n_perturb > 0:
                perturb_indices = np.random.choice(missing_indices, n_perturb, replace=False)
                value_range = np.ptp(col_data[~missing_mask]) or 1.0
                perturbations = np.random.uniform(-1, 1, n_perturb) * perturbation_scale * value_range
                interpolated[perturb_indices] += perturbations
        
        matrix[:, col_idx] = interpolated
    
    return matrix.astype(np.float32)  # âœ… ä¿®å¤ï¼šç§»åˆ°å¾ªç¯å¤–é¢

def initial_process(matrix, threshold=0.8, perturbation_prob=0.1, perturbation_scale=0.1):
    matrix = FirstProcess(matrix, threshold)
    matrix = SecondProcess(matrix, perturbation_prob, perturbation_scale)
    return matrix

def impute(original, causal_matrix, model_params, epochs=100, lr=0.02, gpu_id=None, ifGt=False, gt=None):
    device = torch.device(f'cuda:{gpu_id}' if gpu_id is not None and torch.cuda.is_available() else 'cpu')
    print('missing_count', np.isnan(original).sum())
    
    # é¢„å¤„ç†
    first = FirstProcess(original.copy())
    mask = (~np.isnan(first)).astype(int)
    initial_filled = SecondProcess(first)
    initial_filled_copy = initial_filled.copy()
    
    # ä½¿ç”¨float32ç¡®ä¿å…¼å®¹æ€§
    x = torch.tensor(initial_filled[None, ...], dtype=torch.float32, device=device)
    y = torch.tensor(initial_filled[None, ...], dtype=torch.float32, device=device)
    m = torch.tensor(mask[None, ...], dtype=torch.float32, device=device)
    
    # åˆ›å»ºæ¨¡å‹
    print("causal_matrix.shape", causal_matrix.shape)
    model = ParallelFeatureADDSTCN(
        causal_matrix=causal_matrix,
        model_params=model_params
    ).to(device)

    # ç¼–è¯‘åŠ é€Ÿ
    if hasattr(torch, 'compile'):
        try:
            model = torch.compile(model, mode='reduce-overhead')
        except:
            pass

    opt = torch.optim.Adam(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs, eta_min=lr*0.01)
    scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' and torch.cuda.is_available() else None

    # æ—©åœæœºåˆ¶
    best_loss = float('inf')
    best_imputed = None
    patience = 15
    no_improve_count = 0
    
    # é¢„è®¡ç®—ç»Ÿè®¡é‡
    y_mean = y.mean(dim=1, keepdim=True)
    y_std = y.std(dim=1, keepdim=True)
    quantiles = [0.25, 0.5, 0.75]
    y_quantiles = [torch.quantile(y.float(), q, dim=1, keepdim=True) for q in quantiles]  # âœ… ç¡®ä¿float32

    for epoch in range(epochs):
        opt.zero_grad()
        
        if scaler:
            with torch.cuda.amp.autocast():
                pred = model(x)
                
                # Loss1: è§‚æµ‹å€¼çš„é¢„æµ‹è¯¯å·®
                loss_1 = F.mse_loss(pred * m, y * m)
                
                # âœ… ä¿®å¤ï¼šç¡®ä¿predæ˜¯float32ç±»å‹ç”¨äºç»Ÿè®¡è®¡ç®—
                pred_float = pred.float()  # æ˜ç¡®è½¬æ¢ä¸ºfloat32
                
                pred_mean = pred_float.mean(dim=1, keepdim=True)
                pred_std = pred_float.std(dim=1, keepdim=True)
                
                mean_loss = F.mse_loss(pred_mean, y_mean)
                std_loss = F.mse_loss(pred_std, y_std)
                
                # âœ… ä¿®å¤ï¼šä½¿ç”¨float32ç‰ˆæœ¬è®¡ç®—åˆ†ä½æ•°
                quantile_losses = []
                for i, q in enumerate(quantiles):
                    pred_q = torch.quantile(pred_float, q, dim=1, keepdim=True)
                    quantile_losses.append(F.mse_loss(pred_q, y_quantiles[i]))
                
                loss_3 = (mean_loss + std_loss + sum(quantile_losses)) / (2 + len(quantiles))
                total_loss = 0.6 * loss_1 + 0.4 * loss_3
            
            scaler.scale(total_loss).backward()
            scaler.unscale_(opt)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(opt)
            scaler.update()
        else:
            # æ™®é€šè®­ç»ƒ
            pred = model(x)
            
            loss_1 = F.mse_loss(pred * m, y * m)
            
            # âœ… ç¡®ä¿predæ˜¯float32ç±»å‹
            pred_float = pred.float()
            
            pred_mean = pred_float.mean(dim=1, keepdim=True)
            pred_std = pred_float.std(dim=1, keepdim=True)
            
            mean_loss = F.mse_loss(pred_mean, y_mean)
            std_loss = F.mse_loss(pred_std, y_std)
            
            quantile_losses = []
            for i, q in enumerate(quantiles):
                pred_q = torch.quantile(pred_float, q, dim=1, keepdim=True)  # âœ… ä½¿ç”¨floatç‰ˆæœ¬
                quantile_losses.append(F.mse_loss(pred_q, y_quantiles[i]))
            
            loss_3 = (mean_loss + std_loss + sum(quantile_losses)) / (2 + len(quantiles))
            total_loss = 0.6 * loss_1 + 0.4 * loss_3
            
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            opt.step()
        
        scheduler.step()

        # æ—©åœæ£€æŸ¥
        current_loss = total_loss.item()
        if current_loss < best_loss:
            best_loss = current_loss
            no_improve_count = 0
            with torch.no_grad():
                best_imputed = model(x).float().cpu().squeeze(0).numpy()  # âœ… ç¡®ä¿è½¬æ¢ä¸ºfloat32
        else:
            no_improve_count += 1
            if no_improve_count >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break

        # å‡å°‘æ‰“å°é¢‘ç‡å’Œæ˜¾å­˜æ¸…ç†
        if epoch % 2 == 0:
            print(f"[Epoch {epoch+1}/{epochs}] Loss: {current_loss:.6f}, LR: {scheduler.get_last_lr()[0]:.6f}")
            if device.type == 'cuda':
                torch.cuda.empty_cache()

    # ç”¨æœ€ä¼˜ç»“æœè¿›è¡Œå¡«è¡¥
    res = initial_filled.copy()
    if best_imputed is not None:
        res[mask == 0] = best_imputed[mask == 0]
    
    pd.DataFrame(res).to_csv("result_1.csv", index=False)
    return res, mask, initial_filled_copy


# def impute(original, causal_matrix, model_params, epochs=150, lr=0.02, gpu_id=None, ifGt=False, gt=None):
#     device = torch.device(f'cuda:{gpu_id}' if gpu_id is not None and torch.cuda.is_available() else 'cpu')

#     first = FirstProcess(original.copy())
#     mask = (~np.isnan(first)).astype(int)
#     filled = SecondProcess(first)

#     # æ„é€ å¼ é‡
#     x = torch.tensor(filled.T[None, ...], dtype=torch.float32, device=device)
#     y = torch.tensor(filled[None, ...], dtype=torch.float32, device=device).transpose(1, 2)
#     m = torch.tensor(mask[None, ...], dtype=torch.float32, device=device).transpose(1, 2)

#     model = MultiADDSTCN(
#         causal_mask=causal_matrix,
#         cuda=device.type == 'cuda',
#         **model_params
#     ).to(device)

#     opt = torch.optim.Adam(model.parameters(), lr=lr)
#     best_loss = float('inf')
#     best_imputed = None

#     for epoch in range(epochs):
#         opt.zero_grad()
#         pred = model(x)  # (1, T, N)

#         # Loss1: è§‚æµ‹å€¼çš„é¢„æµ‹è¯¯å·®
#         loss_1 = F.mse_loss(pred * m, y * m)

#         # Loss2: é’ˆå¯¹ç¼ºå¤±ä½ç½®ä¸gtçš„ä¸€è‡´æ€§ï¼ˆä¸è¯„ä¼°å‡½æ•°ä¿æŒä¸€è‡´ï¼‰
#         if ifGt and gt is not None:
#             mask_np = (~np.isnan(original)).astype(int)
#             missing_mask_np = (1 - mask_np).astype(bool)

#             pred_np = pred.detach().cpu().squeeze(0).numpy()
#             gt_np = gt.copy()

#             pred_missing = pred_np[missing_mask_np]
#             gt_missing = gt_np[missing_mask_np]

#             pred_tensor = torch.tensor(pred_missing, dtype=torch.float32, device=device, requires_grad=True)
#             gt_tensor = torch.tensor(gt_missing, dtype=torch.float32, device=device)

#             loss_2 = F.mse_loss(pred_tensor, gt_tensor)
#         else:
#             loss_2 = ((pred * m - y * m) ** 2).sum() / m.sum()

#         # Loss3: åæ–¹å·®çŸ©é˜µå¯¹é½
#         pred_np = pred.squeeze(0).T
#         y_np = y.squeeze(0).T
#         if pred_np.shape[1] > 1:
#             try:
#                 cov_pred = torch.cov(pred_np)
#                 cov_y = torch.cov(y_np)
#                 loss_3 = F.mse_loss(cov_pred, cov_y)
#             except:
#                 loss_3 = torch.tensor(0.0, device=device, requires_grad=True)
#         else:
#             loss_3 = torch.tensor(0.0, device=device, requires_grad=True)

#         # Loss4: RBFæ ¸æ˜ å°„å¯¹é½
#         def rbf_kernel(mat, sigma=1.0):
#             if mat.shape[0] <= 1:
#                 return torch.zeros((1, 1), device=mat.device, requires_grad=True)
#             dist = torch.cdist(mat, mat, p=2) ** 2
#             return torch.exp(-dist / (2 * sigma ** 2))

#         try:
#             K_pred = rbf_kernel(pred_np)
#             K_y = rbf_kernel(y_np)
#             loss_4 = F.mse_loss(K_pred, K_y)
#         except:
#             loss_4 = torch.tensor(0.0, device=device, requires_grad=True)

#         # åŠ æƒæ€»æŸå¤±
#         total_loss = loss_1 + 0 * loss_2 + 0 * loss_3 + 0 * loss_4
#         print(f"[Epoch {epoch+1}/{epochs}] Total Loss: {total_loss.item():.6f}")
#         total_loss.backward()
#         opt.step()

#         # ä¿å­˜æœ€ä½³é¢„æµ‹ç»“æœ
#         if total_loss.item() < best_loss:
#             best_loss = total_loss.item()
#             with torch.no_grad():
#                 best_imputed = model(x).cpu().squeeze(0).numpy()

#     # ç”¨æœ€ä¼˜ç»“æœè¿›è¡Œå¡«è¡¥
#     imputed = best_imputed
#     filled[mask == 0] = imputed[mask == 0]
#     return filled




# def impute(original, causal_matrix, model_params, epochs=150, lr=0.02, gpu_id=None):
#     if gpu_id is not None and torch.cuda.is_available():
#         device = torch.device(f'cuda:{gpu_id}')
#     else:
#         device = torch.device('cpu')
#     original_copy = original.copy()
#     # é˜¶æ®µ1: å¡«è¡¥ç©ºåˆ— + é«˜é‡å¤åˆ—
#     first_stage_initial_filled = FirstProcess(original_copy)
#     # é˜¶æ®µ2: æ•°å€¼æ‰°åŠ¨å¢å¼º
#     initial_filled = SecondProcess(first_stage_initial_filled)

#     mask = (~np.isnan(first_stage_initial_filled)).astype(int)
#     sequence_len, total_features = initial_filled.shape
#     final_filled = initial_filled.copy()

#     for target in range(total_features):
#         # é€‰æ‹©å› æœç‰¹å¾
#         inds = list(np.where(causal_matrix[:, target] == 1)[0])
#         if target not in inds:
#             inds.append(target)
#         else:
#             inds.remove(target)
#             inds.append(target)
#         inds = inds[:3] + [target]  # ä¿ç•™

#         # æ„é€ æ»åç›®æ ‡å˜é‡
#         target_shifted = np.roll(initial_filled[:, target], 1)
#         target_shifted[0] = 0.0
#         x_data = np.concatenate([initial_filled[:, inds], target_shifted[:, None]], axis=1)

#         x = torch.tensor(x_data.T[np.newaxis, ...], dtype=torch.float32).to(device)
#         y = torch.tensor(initial_filled[:, target][np.newaxis, :, None], dtype=torch.float32).to(device)
#         m = torch.tensor((mask[:, target] == 1)[np.newaxis, :, None], dtype=torch.float32).to(device)

#         # æ„å»ºæ¨¡å‹
#         input_dim = x.shape[1]
#         model = ADDSTCN(target, input_size=input_dim, cuda=(device != torch.device('cpu')), **model_params).to(device)

#         optimizer = torch.optim.Adam(model.parameters(), lr=lr)

#         # ç¼–è¯‘åŠ é€Ÿ
#         if hasattr(torch, 'compile'):
#             try:
#                 model = torch.compile(model)
#             except:
#                 pass

#         # è®­ç»ƒ
#         for epoch in range(1, epochs + 1):
#             model.train()
#             optimizer.zero_grad()
#             pred = model(x)
#             loss = F.mse_loss(pred * m, y * m)
#             loss.backward()
#             optimizer.step()

#         # æ¨ç†
#         model.eval()
#         with torch.no_grad():
#             out = model(x).squeeze().cpu().numpy()
#             to_fill = np.where(mask[:, target] == 0)
#             to_fill_filtered = to_fill[0]
#             if len(to_fill_filtered) > 0:
#                 final_filled[to_fill_filtered, target] = out[to_fill_filtered]

#     return final_filled

def impute_wrapper(task_queue, result_queue, causal_matrix, model_params, epochs, lr, output_dir):
    while True:
        task = task_queue.get()
        if task is None:
            break
        idx, file_path, gpu_id = task

        try:
            if gpu_id is not None:
                os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)

            df = pd.read_csv(file_path)
            data = df.values.astype(np.float32)

            imputed, mask, initial = impute(data, causal_matrix, model_params, epochs, lr, gpu_id=0)

            # æ„é€ ä¿å­˜è·¯å¾„
            filename = os.path.basename(file_path).replace('.csv', '_imputed.csv')
            save_path = os.path.join(output_dir, filename)
            pd.DataFrame(imputed).to_csv(save_path, index=False)

            result_queue.put((idx, file_path, save_path))
        except Exception as e:
            result_queue.put((idx, file_path, f"Error: {e}"))


def parallel_impute(
    file_paths,  # è¿™ä¸ªå‚æ•°åº”è¯¥æ”¹åä¸º data_dir æ›´æ¸…æ¥š
    causal_matrix,
    model_params,
    epochs=150,
    lr=0.02,
    simultaneous_per_gpu=2,
    max_workers=None,
    output_dir="imputed_results"
):
    try:
        set_start_method('spawn')
    except RuntimeError:
        pass

    os.makedirs(output_dir, exist_ok=True)

    # âœ… ä¿®å¤ï¼šæ­£ç¡®å¤„ç†è¾“å…¥è·¯å¾„
    if isinstance(file_paths, str) and os.path.isdir(file_paths):
        # å¦‚æœä¼ å…¥çš„æ˜¯ç›®å½•è·¯å¾„ï¼Œè·å–æ‰€æœ‰CSVæ–‡ä»¶
        file_list = [os.path.join(file_paths, f) for f in os.listdir(file_paths) if f.endswith('.csv')]
        print(f"ä»ç›®å½• '{file_paths}' æ‰¾åˆ° {len(file_list)} ä¸ªCSVæ–‡ä»¶")
    elif isinstance(file_paths, list):
        # å¦‚æœä¼ å…¥çš„æ˜¯æ–‡ä»¶åˆ—è¡¨
        file_list = file_paths
        print(f"æ”¶åˆ°æ–‡ä»¶åˆ—è¡¨ï¼Œå…± {len(file_list)} ä¸ªæ–‡ä»¶")
    else:
        raise ValueError("file_paths must be a directory path or list of file paths")

    if len(file_list) == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶")
        return {}

    # âœ… æ·»åŠ è°ƒè¯•ä¿¡æ¯
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"å‰3ä¸ªæ–‡ä»¶: {file_list[:3]}")

    num_gpus = torch.cuda.device_count()
    if num_gpus == 0:
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUæ¨¡å¼")
        # CPUæ¨¡å¼ä¸‹ä¹Ÿå¯ä»¥è¿è¡Œï¼Œä¸è¦æŠ›å‡ºé”™è¯¯
        total_workers = min(4, len(file_list))  # CPUæ¨¡å¼é™åˆ¶è¿›ç¨‹æ•°
    else:
        total_workers = num_gpus * simultaneous_per_gpu
        
    if max_workers:
        total_workers = min(total_workers, max_workers)

    print(f"æ€»å·¥ä½œè¿›ç¨‹æ•°: {total_workers}")

    task_queue = Queue()
    result_queue = Queue()

    # æ·»åŠ ä»»åŠ¡ - ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶åˆ—è¡¨
    for idx, file_path in enumerate(file_list):  # âœ… ä½¿ç”¨ file_list è€Œä¸æ˜¯ file_paths
        assigned_gpu = idx % num_gpus if num_gpus > 0 else None
        task_queue.put((idx, file_path, assigned_gpu))
        
        # âœ… æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if idx < 5:
            print(f"ä»»åŠ¡ {idx}: {file_path} -> GPU {assigned_gpu}")

    # æ·»åŠ ç»ˆæ­¢ä¿¡å·
    for _ in range(total_workers):
        task_queue.put(None)

    # å¯åŠ¨ workers
    workers = []
    for worker_id in range(total_workers):
        p = Process(
            target=impute_wrapper,
            args=(task_queue, result_queue, causal_matrix, model_params, epochs, lr, output_dir)
        )
        p.start()
        workers.append(p)
        print(f"å¯åŠ¨å·¥ä½œè¿›ç¨‹ {worker_id+1}/{total_workers}")

    results = {}
    completed_count = 0
    
    # âœ… ä¿®å¤è¿›åº¦æ¡ - ä½¿ç”¨æ­£ç¡®çš„æ€»æ•°
    with tqdm(total=len(file_list), desc="Imputing and Saving") as pbar:
        for _ in range(len(file_list)):  # âœ… ä½¿ç”¨ file_list çš„é•¿åº¦
            idx, path, result = result_queue.get()
            results[path] = result
            completed_count += 1
            
            # âœ… æ·»åŠ è¯¦ç»†çš„ç»“æœä¿¡æ¯
            if isinstance(result, str) and result.startswith("Error"):
                print(f"âŒ æ–‡ä»¶ {os.path.basename(path)} å¤±è´¥: {result}")
            else:
                print(f"âœ… æ–‡ä»¶ {os.path.basename(path)} å®Œæˆ: {result}")
            
            pbar.update(1)

    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    for p in workers:
        p.join()

    print(f"æ€»ä½“å®Œæˆæƒ…å†µ: {completed_count}/{len(file_list)} ä¸ªæ–‡ä»¶")
    
    # âœ… æ£€æŸ¥è¾“å‡ºç›®å½•
    if os.path.exists(output_dir):
        output_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
        print(f"è¾“å‡ºç›®å½• '{output_dir}' ä¸­æœ‰ {len(output_files)} ä¸ªæ–‡ä»¶")
        if len(output_files) > 0:
            print(f"å‰3ä¸ªè¾“å‡ºæ–‡ä»¶: {output_files[:3]}")
    else:
        print(f"âŒ è¾“å‡ºç›®å½• '{output_dir}' ä¸å­˜åœ¨")

    return results
def agregate(initial_filled_array, n_cluster):
    # Step 1: æ¯ä¸ªæ ·æœ¬æŒ‰åˆ—å–å‡å€¼ï¼Œæ„é€ èšç±»è¾“å…¥
    data = np.array([np.nanmean(x, axis=0) for x in initial_filled_array])

    # Step 2: KMeans èšç±»
    km = KMeans(n_clusters=n_cluster, n_init=10, random_state=0)
    labels = km.fit_predict(data)

    # Step 3: é€ç±»æ‰¾ä»£è¡¨æ ·æœ¬ï¼Œå¸¦è¿›åº¦æ¡
    idx_arr = []
    for k in tqdm(range(n_cluster), desc="é€‰æ‹©æ¯ç°‡ä»£è¡¨æ ·æœ¬"):
        idxs = np.where(labels == k)[0]
        if len(idxs) == 0:
            continue
        cluster_data = data[idxs]
        dists = np.linalg.norm(cluster_data - km.cluster_centers_[k], axis=1)
        best_idx = idxs[np.argmin(dists)]
        idx_arr.append(int(best_idx))

    return idx_arr

def causal_discovery(original_matrix_arr, n_cluster=5, isStandard=False, standard_cg=None,
                     params={
                         'layers': 6,
                         'kernel_size': 6,
                         'dilation_c': 4,
                         'optimizername': 'Adam',
                         'lr': 0.02,
                         'epochs': 100,
                         'significance': 1.2,
                     }):
    if isStandard:
        if standard_cg is None:
            raise ValueError("standard_cg must be provided when isStandard is True")
        return pd.read_csv(standard_cg, header=None).values

    # Step 1: æ‰¹é‡é¢„å¤„ç†
    initial_matrix_arr = []
    batch_size = 100
    
    for i in tqdm(range(0, len(original_matrix_arr), batch_size), desc="æ‰¹é‡é¢„å¤„ç†"):
        batch = original_matrix_arr[i:i+batch_size]
        batch_results = [initial_process(matrix) for matrix in batch]
        initial_matrix_arr.extend(batch_results)
        
        if i % (batch_size * 5) == 0:
            gc.collect()

    # Step 2: èšç±»å¹¶æå–ä»£è¡¨æ ·æœ¬
    idx_arr = agregate(initial_matrix_arr, n_cluster)
    data_list = [initial_matrix_arr[idx] for idx in idx_arr]
    params_list = [params] * len(data_list)

    # Step 3: å¤š GPU å¹¶è¡Œå› æœå‘ç°
    results = parallel_compute_causal_matrices(data_list, params_list)

    # Step 4: æ±‡æ€»ç»“æœ
    cg_total = None
    for matrix in results:
        if matrix is None:
            continue
        if cg_total is None:
            cg_total = matrix.copy()
        else:
            cg_total += matrix

    if cg_total is None:
        raise RuntimeError("æ‰€æœ‰ä»»åŠ¡éƒ½å¤±è´¥ï¼Œæœªèƒ½å¾—åˆ°æœ‰æ•ˆçš„å› æœçŸ©é˜µ")

    # # Step 5: é€‰ Top-3 æ„å»ºæœ€ç»ˆå› æœå›¾
    # np.fill_diagonal(cg_total, 0)
    # new_matrix = np.zeros_like(cg_total)
    # for col in range(cg_total.shape[1]):
    #     col_values = cg_total[:, col]
    #     if np.count_nonzero(col_values) < 3:
    #         new_matrix[:, col] = 1
    #     else:
    #         top3 = np.argsort(col_values)[-3:]
    #         new_matrix[top3, col] = 1
       # Step 5: é€‰ Top-4 æ„å»ºæœ€ç»ˆå› æœå›¾
    np.fill_diagonal(cg_total, 0)
    new_matrix = np.zeros_like(cg_total)
    for col in range(cg_total.shape[1]):
        col_values = cg_total[:, col]
        if np.count_nonzero(col_values) < 4:
            new_matrix[:, col] = 1
        else:
            top5 = np.argsort(col_values)[-4:]
            new_matrix[top5, col] = 1
    return new_matrix

# ================================
# 1. å•æ–‡ä»¶è¯„ä¼°å‡½æ•°
# ================================
def mse_evaluate_single_file(mx, causal_matrix, gpu_id=0, device=None):
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ground truth
    gt = mx.copy()
    gt2 = gt.copy()
    pd.DataFrame(gt).to_csv("1.csv", index=False)
    # éšæœº mask ç”Ÿæˆç¼ºå¤±
    X = mar_logistic(mx, obs_rate=0.2, missing_rate=0.1)
    X = X[np.newaxis, ...]  # å¢åŠ ä¸€ä¸ªç»´åº¦
    X = mnar_x(X, offset=0.05)
    X = mcar(X, p=0.05)
    X = X.squeeze(0)  # å»æ‰å¤šä½™çš„ç»´åº¦
    Mask = (~np.isnan(X)).astype(int)
    pd.DataFrame(X).to_csv("2.csv", index=False)
    # # mask: è§‚æµ‹ä¸º 1ï¼Œç¼ºå¤±ä¸º 0
    # M = (~np.isnan(X)).astype(int)
    # missing_place = 1 - M
    Mask = (~np.isnan(X)).astype(int)
    # æ©ç ç‰ˆ MSEï¼Œåªåœ¨ç¼ºå¤±ä½ç½®è¯„ä¼°
    def mse(a, b, mask):
        a = torch.as_tensor(a, dtype=torch.float32, device=device)
        b = torch.as_tensor(b, dtype=torch.float32, device=device)
        mask = torch.as_tensor(mask, dtype=torch.float32, device=device)
        mask = 1- mask
        element_wise_error = (a - b) ** 2  
        
        pd.DataFrame((element_wise_error*mask).cpu().numpy()).to_csv("element_wise_error.csv", index=False)
        pd.DataFrame(a.cpu().numpy()).to_csv("a.csv", index=False)
        pd.DataFrame(b.cpu().numpy()).to_csv("b.csv", index=False)
        pd.DataFrame(mask.cpu().numpy()).to_csv("mask.csv", index=False)
        pd.DataFrame((a*mask).cpu().numpy()).to_csv("a*c.csv", index=False)
        pd.DataFrame((b*mask).cpu().numpy()).to_csv("b*c.csv", index=False)
        
        # è®¡ç®— masked MSE
        masked_error = F.mse_loss(a * mask, b * mask).item()

        return masked_error

    res = {}

    # æˆ‘çš„æ¨¡å‹è¯„ä¼°
    # print("å¼€å§‹æ‰§è¡Œ my_model...")
    imputed_result, mask, initial_processed = impute(X, causal_matrix,
                            model_params={'num_levels':10, 'kernel_size': 8, 'dilation_c': 2},
                            epochs=100, lr=0.02, gpu_id=gpu_id, ifGt=True, gt=gt)
    # print("imputed_result.shape", imputed_result.shape, "gt2.shape", gt2.shape, "mask.shape", mask.shape)
    res['my_model'] = mse(imputed_result, gt2, mask)
    def is_reasonable_mse(mse_value, threshold=10000.0):
        return (not np.isnan(mse_value) and 
                not np.isinf(mse_value) and 
                0 <= mse_value <= threshold)

    # baseline æ–¹æ³•
    baseline = [
        ('initial_process', initial_process),
        ('zero_impu', zero_impu),
        ('mean_impu', mean_impu),
        ('median_impu', median_impu),
        ('mode_impu', mode_impu),
        ('random_impu', random_impu), ('knn_impu', knn_impu),
        ('ffill_impu', ffill_impu), ('bfill_impu', bfill_impu),
        ('miracle_impu', miracle_impu), ('saits_impu', saits_impu),
        ('timemixerpp_impu', timemixerpp_impu), 
        ('tefn_impu', tefn_impu),('timesnet_impu', timesnet_impu),
        ('tsde_impu', tsde_impu)
    ]

    for name, fn in baseline:
        print(f"å¼€å§‹æ‰§è¡Œ {name}...")
        result = fn(X)
        if np.any(np.abs(result) > 1e6):
            print(f"âŒ {name}: å¡«è¡¥ç»“æœåŒ…å«å¼‚å¸¸å¤§å€¼ (max: {np.max(np.abs(result)):.2e})")
            res[name] = float('nan')
        else:
            mse_value = mse(result, gt, Mask)
            if is_reasonable_mse(mse_value):
                res[name] = mse_value
                print(f"âœ… {name}: {mse_value:.6f}")
            else:
                print(f"âŒ {name}: MSEå¼‚å¸¸ ({mse_value:.2e})")
                res[name] = float('nan')

    print(f"æ‰€æœ‰ç»“æœ: {res}")
    return res


# ================================
# 2. ç”¨äº Pool çš„åŒ…è£…å‡½æ•°ï¼ˆæ¯ä¸ªä»»åŠ¡ï¼‰
# ================================
def worker_wrapper(args):
    idx, mx, causal_matrix, gpu_id = args
    gt = mx.copy()
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    # ç¡®ä¿PyTorchä½¿ç”¨æ­£ç¡®çš„è®¾å¤‡
    if torch.cuda.is_available():
        torch.cuda.set_device(0)  # åœ¨å­è¿›ç¨‹ä¸­ï¼ŒGPU 0å°±æ˜¯åˆ†é…ç»™çš„GPU
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
    
    # ä¼ é€’æ­£ç¡®çš„è®¾å¤‡
    res = mse_evaluate_single_file(mx, causal_matrix, gpu_id=0, device=device)  # â† è¿™é‡Œæ”¹ä¸º0
    return idx, res

# ================================
# 3. å¹¶è¡Œè°ƒåº¦å‡½æ•°ï¼ˆè¿›ç¨‹æ± å®ç°ï¼‰
# ================================
def parallel_mse_evaluate(res_list, causal_matrix, simultaneous_per_gpu=3):
    num_gpus = torch.cuda.device_count()

    if num_gpus == 0:
        print("[INFO] æ²¡æœ‰å¯ç”¨ GPUï¼Œä½¿ç”¨ CPU é¡ºåºè¯„ä¼°")
        all_res = [mse_evaluate_single_file(x, causal_matrix)
                   for x in tqdm(res_list, desc="CPU")]
        return {k: float(np.mean([d[k] for d in all_res]))
                for k in all_res[0]}

    # æ ¹æ® GPU æ•°é‡å’Œæ¯å¼ å¡å¯å¹¶è¡Œä»»åŠ¡æ•°ï¼Œè®¾ç½®è¿›ç¨‹æ± å¤§å°
    max_workers = num_gpus * simultaneous_per_gpu
    print(f"[INFO] ä½¿ç”¨ {num_gpus} ä¸ª GPUï¼Œæ¯ä¸ª GPU æœ€å¤šå¹¶è¡Œ {simultaneous_per_gpu} ä¸ªä»»åŠ¡ï¼Œæ€»è¿›ç¨‹æ•°: {max_workers}")

    # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ†é…å¯¹åº”çš„ GPU
    gpu_ids = [i % num_gpus for i in range(len(res_list))]
    args_list = [(i, res_list[i], causal_matrix, gpu_ids[i]) for i in range(len(res_list))]

    with mp.Pool(processes=max_workers) as pool:
        results = list(tqdm(pool.imap(worker_wrapper, args_list), total=len(args_list), desc="Allâ€‘tasks"))

    results.sort(key=lambda x: x[0])  # æ¢å¤é¡ºåº
    only_result_dicts = [res for _, res in results]

    avg = {}
    for k in only_result_dicts[0]:
        values = [r[k] for r in only_result_dicts]
        valid_values = [v for v in values if not np.isnan(v)]
        
        if len(valid_values) > 0:
            avg[k] = float(np.nanmean(values))
            print(f"ğŸ“Š {k}: {len(valid_values)}/{len(values)} ä¸ªæœ‰æ•ˆå€¼ï¼Œå¹³å‡: {avg[k]:.6f}")
        else:
            avg[k] = float('nan')
            print(f"âŒ {k}: æ‰€æœ‰å€¼éƒ½æ˜¯ NaN")
    pd.DataFrame([{'Method': k, 'Average_MSE': v} for k, v in avg.items()]) \
        .to_csv("mse_evaluation_results.csv", index=False)

    return avg