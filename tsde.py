import numpy as np
import torch
import torch.nn as nn
import yaml
import json
import os
from typing import Optional

# è®¾ç½®éšæœºç§å­
def set_seed(seed):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

# âœ… ä¿®å¤SimpleDiffusionModelï¼Œç¡®ä¿bufferåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
class SimpleDiffusionModel(nn.Module):
    def __init__(self, input_dim, hidden_dim=128, num_steps=50):
        super().__init__()
        self.num_steps = num_steps
        self.input_dim = input_dim
        
        # ç®€åŒ–çš„å»å™ªç½‘ç»œ
        self.net = nn.Sequential(
            nn.Linear(input_dim + 1, hidden_dim),  # +1 for time embedding
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )
        
        # âœ… æ‰©æ•£è°ƒåº¦ - è¿™äº›bufferä¼šè‡ªåŠ¨è·Ÿéšæ¨¡å‹è®¾å¤‡
        self.register_buffer('betas', torch.linspace(0.0001, 0.02, num_steps))
        self.register_buffer('alphas', 1 - self.betas)
        self.register_buffer('alphas_cumprod', torch.cumprod(self.alphas, dim=0))
    
    def forward(self, x, t):
        # âœ… ç¡®ä¿æ—¶é—´åµŒå…¥åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        device = next(self.parameters()).device
        if t.device != device:
            t = t.to(device)
        
        # æ—¶é—´åµŒå…¥
        t_emb = t.float().unsqueeze(-1) / self.num_steps
        x_t = torch.cat([x, t_emb], dim=-1)
        return self.net(x_t)

# âœ… ä¿®å¤SimpleTSDEç±»ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
class SimpleTSDE(nn.Module):
    def __init__(self, feature_dim, seq_len, device="cuda"):
        super().__init__()
        self.feature_dim = feature_dim
        self.seq_len = seq_len
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        
        # æ‰©æ•£æ¨¡å‹
        self.diffusion = SimpleDiffusionModel(feature_dim)
        
        # âœ… æ—¶é—´å’Œç‰¹å¾åµŒå…¥ - ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        self.time_emb = nn.Embedding(seq_len, 64)
        self.feature_emb = nn.Linear(feature_dim, 64)
        
        # èåˆå±‚
        self.fusion = nn.Linear(64 * 2, feature_dim)
        
        # âœ… ç«‹å³ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.to(self.device)
        
    def get_embeddings(self, x, mask, timepoints):
        # âœ… ç¡®ä¿timepointsåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if timepoints.device != self.device:
            timepoints = timepoints.to(self.device)
        
        # æ—¶é—´åµŒå…¥
        time_emb = self.time_emb(timepoints.long())  # (B, T, 64)
        
        # ç‰¹å¾åµŒå…¥
        feat_emb = self.feature_emb(x)  # (B, T, 64)
        
        # èåˆ
        combined = torch.cat([time_emb, feat_emb], dim=-1)  # (B, T, 128)
        return self.fusion(combined)  # (B, T, F)
    
    def impute(self, observed_data, mask, n_samples=50):
        B, T, F = observed_data.shape
        device = self.device  # âœ… ä½¿ç”¨æ¨¡å‹çš„è®¾å¤‡
        
        # âœ… ç¡®ä¿è¾“å…¥æ•°æ®åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if observed_data.device != device:
            observed_data = observed_data.to(device)
        if mask.device != device:
            mask = mask.to(device)
        
        # âœ… åœ¨æ¨¡å‹è®¾å¤‡ä¸Šåˆ›å»ºæ—¶é—´ç‚¹
        timepoints = torch.arange(T, device=device).unsqueeze(0).repeat(B, 1)
        
        # è·å–æ¡ä»¶åµŒå…¥
        cond_emb = self.get_embeddings(observed_data, mask, timepoints)
        
        samples = []
        
        # æ˜¾ç¤ºè¿›åº¦
        try:
            from tqdm import tqdm
            sample_iterator = tqdm(range(n_samples), desc="ç”Ÿæˆæ ·æœ¬", leave=False)
        except ImportError:
            sample_iterator = range(n_samples)
        
        for sample_idx in sample_iterator:
            # âœ… åœ¨æ­£ç¡®è®¾å¤‡ä¸Šä»å™ªå£°å¼€å§‹
            x_t = torch.randn_like(observed_data, device=device)
            
            # åå‘æ‰©æ•£è¿‡ç¨‹
            for t in reversed(range(self.diffusion.num_steps)):
                # âœ… ç¡®ä¿æ‰€æœ‰å¼ é‡éƒ½åœ¨åŒä¸€è®¾å¤‡ä¸Š
                t_tensor = torch.full((B,), t, device=device, dtype=torch.long)
                
                # æ‰¹é‡å¤„ç†æ‰€æœ‰æ—¶é—´æ­¥ï¼Œé¿å…å¾ªç¯
                x_reshaped = x_t.view(-1, F)  # (B*T, F)
                cond_reshaped = cond_emb.view(-1, F)  # (B*T, F)
                t_expanded = t_tensor.unsqueeze(1).repeat(1, T).view(-1)  # (B*T,)
                
                # æ‰¹é‡é¢„æµ‹å™ªå£°
                x_input = x_reshaped + 0.1 * cond_reshaped
                noise_pred = self.diffusion(x_input, t_expanded)
                
                # é‡å¡‘å›åŸæ¥çš„å½¢çŠ¶
                noise_pred = noise_pred.view(B, T, F)
                
                # å»å™ªæ­¥éª¤
                if t > 0:
                    alpha = self.diffusion.alphas[t]
                    alpha_cumprod = self.diffusion.alphas_cumprod[t]
                    
                    # ç®€åŒ–çš„DDPMæ›´æ–°
                    x_t = (x_t - (1 - alpha) / torch.sqrt(1 - alpha_cumprod) * noise_pred) / torch.sqrt(alpha)
                    
                    # æ·»åŠ å™ªå£°
                    if t > 1:
                        noise = torch.randn_like(x_t, device=device)
                        x_t = x_t + torch.sqrt(self.diffusion.betas[t]) * noise
                else:
                    x_t = (x_t - noise_pred) / torch.sqrt(self.diffusion.alphas_cumprod[0])
            
            # ç»“åˆè§‚æµ‹æ•°æ®
            x_t = mask * observed_data + (1 - mask) * x_t
            samples.append(x_t)
            
            # å®šæœŸæ¸…ç†GPUç¼“å­˜
            if device.type == 'cuda' and sample_idx % 10 == 0:
                torch.cuda.empty_cache()
        
        # è¿”å›æ‰€æœ‰æ ·æœ¬
        return torch.stack(samples, dim=1)  # (B, n_samples, T, F)

def load_model_from_checkpoint(model_path, config_path, data_shape, device="cpu"):
    """ä»æ£€æŸ¥ç‚¹åŠ è½½æ¨¡å‹"""
    seq_len, feature_dim = data_shape
    
    # âœ… åˆ›å»ºæ¨¡å‹æ—¶ä¼ å…¥è®¾å¤‡ä¿¡æ¯
    model = SimpleTSDE(feature_dim, seq_len, device)
    
    if os.path.exists(model_path):
        try:
            # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¯èƒ½ä¸å®Œå…¨å…¼å®¹ï¼‰
            checkpoint = torch.load(model_path, map_location=device)
            # åªåŠ è½½å…¼å®¹çš„æƒé‡
            model_dict = model.state_dict()
            compatible_dict = {k: v for k, v in checkpoint.items() 
                             if k in model_dict and v.shape == model_dict[k].shape}
            model_dict.update(compatible_dict)
            model.load_state_dict(model_dict)
            print(f"âœ… åŠ è½½äº† {len(compatible_dict)} ä¸ªå…¼å®¹çš„æƒé‡å‚æ•°")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½é¢„è®­ç»ƒæƒé‡: {e}")
            print("ä½¿ç”¨éšæœºåˆå§‹åŒ–")
    
    return model.to(device)

def impute_missing_data(
    data: np.ndarray,
    missing_mask: Optional[np.ndarray] = None,
    model_folder: Optional[str] = None,
    n_samples: int = 50,
    device: str = "cuda"  # âœ… é»˜è®¤ä½¿ç”¨GPU
) -> np.ndarray:
    """
    ä½¿ç”¨TSDEå¡«è¡¥ç¼ºå¤±æ•°æ®çš„ä¸»å‡½æ•°ï¼ˆGPUä¼˜åŒ–ç‰ˆï¼‰
    
    Args:
        data: äºŒç»´numpyæ•°ç»„ (æ—¶é—´æ­¥, ç‰¹å¾æ•°)ï¼ŒåŒ…å«NaNè¡¨ç¤ºç¼ºå¤±å€¼
        missing_mask: å¯é€‰ï¼Œç¼ºå¤±æ©ç  (1=è§‚æµ‹å€¼, 0=ç¼ºå¤±å€¼)
        model_folder: å¯é€‰ï¼Œé¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„
        n_samples: ç”Ÿæˆæ ·æœ¬æ•°ï¼Œç”¨äºå–ä¸­ä½æ•°
        device: è®¡ç®—è®¾å¤‡ ("cuda", "cpu", æˆ– "cuda:0", "cuda:1" ç­‰)
        
    Returns:
        å¡«è¡¥åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    
    # è¾“å…¥éªŒè¯
    if not isinstance(data, np.ndarray) or len(data.shape) != 2:
        raise ValueError("è¾“å…¥æ•°æ®å¿…é¡»æ˜¯äºŒç»´numpyæ•°ç»„")
    
    seq_len, feature_dim = data.shape
    
    # âœ… æ™ºèƒ½è®¾å¤‡é€‰æ‹©
    if device.startswith("cuda") and torch.cuda.is_available():
        device = torch.device(device)
        print(f"ğŸš€ ä½¿ç”¨GPU: {device}")
    else:
        device = torch.device("cpu")
        print("âš ï¸ ä½¿ç”¨CPU (GPUä¸å¯ç”¨)")
    
    # å¤„ç†ç¼ºå¤±æ©ç 
    if missing_mask is None:
        missing_mask = ~np.isnan(data)
        data_clean = np.nan_to_num(data, nan=0.0)
    else:
        data_clean = data.copy()
        data_clean[~missing_mask] = 0.0
    
    # âœ… ä¼˜åŒ–å¼ é‡è½¬æ¢å’Œå†…å­˜ç®¡ç†
    data_tensor = torch.FloatTensor(data_clean).unsqueeze(0).to(device, non_blocking=True)  # (1, T, F)
    mask_tensor = torch.FloatTensor(missing_mask.astype(float)).unsqueeze(0).to(device, non_blocking=True)
    
    # åŠ è½½æˆ–åˆ›å»ºæ¨¡å‹
    if model_folder and os.path.exists(model_folder):
        model_path = os.path.join(model_folder, "model.pth")
        config_path = os.path.join(model_folder, "config.json")
        model = load_model_from_checkpoint(model_path, config_path, (seq_len, feature_dim), device)
        print(f"ğŸ”„ å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_folder}")
    else:
        model = SimpleTSDE(feature_dim, seq_len, device)
        print("ğŸ”„ ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¨¡å‹")
    
    # âœ… ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    model = model.to(device)
    model.eval()
    set_seed(42)
    
    # âœ… GPUä¼˜åŒ–çš„å¡«è¡¥è¿‡ç¨‹
    with torch.no_grad():
        if device.type == 'cuda':
            torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
        
        print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆ {n_samples} ä¸ªæ ·æœ¬...")
        
        # ç”Ÿæˆå¤šä¸ªæ ·æœ¬
        samples = model.impute(data_tensor, mask_tensor, n_samples)
        
        # å–ä¸­ä½æ•°ä½œä¸ºæœ€ç»ˆç»“æœ
        result = torch.median(samples, dim=1)[0]  # (1, T, F)
        
        # âœ… å¼‚æ­¥ä¼ è¾“å›CPU
        result_np = result.cpu().numpy().squeeze(0)  # (T, F)
        
        if device.type == 'cuda':
            torch.cuda.empty_cache()  # æ¸…ç†GPUç¼“å­˜
    
    print("âœ… å¡«è¡¥å®Œæˆ!")
    return result_np

# âœ… æ·»åŠ è®¾å¤‡æ£€æŸ¥å‡½æ•°
def check_device_consistency(model, *tensors):
    """æ£€æŸ¥æ¨¡å‹å’Œå¼ é‡æ˜¯å¦åœ¨åŒä¸€è®¾å¤‡ä¸Š"""
    model_device = next(model.parameters()).device
    
    for i, tensor in enumerate(tensors):
        if tensor.device != model_device:
            print(f"âš ï¸ è®¾å¤‡ä¸åŒ¹é…: æ¨¡å‹åœ¨ {model_device}, å¼ é‡ {i} åœ¨ {tensor.device}")
            return False
    
    print(f"âœ… æ‰€æœ‰ç»„ä»¶éƒ½åœ¨è®¾å¤‡ {model_device} ä¸Š")
    return True

# âœ… å¤šGPUå¹¶è¡Œç‰ˆæœ¬
def impute_missing_data_parallel(
    data: np.ndarray,
    missing_mask: Optional[np.ndarray] = None,
    model_folder: Optional[str] = None,
    n_samples: int = 50,
    gpu_ids: list = [0]  # æŒ‡å®šä½¿ç”¨çš„GPU IDåˆ—è¡¨
) -> np.ndarray:
    """ä½¿ç”¨å¤šGPUå¹¶è¡Œçš„TSDEå¡«è¡¥"""
    
    if len(gpu_ids) == 1:
        # å•GPUæƒ…å†µ
        device = f"cuda:{gpu_ids[0]}"
        return impute_missing_data(data, missing_mask, model_folder, n_samples, device)
    
    # å¤šGPUå¹¶è¡Œå¤„ç†
    print(f"ğŸš€ ä½¿ç”¨å¤šGPUå¹¶è¡Œ: {gpu_ids}")
    
    seq_len, feature_dim = data.shape
    samples_per_gpu = n_samples // len(gpu_ids)
    
    import concurrent.futures
    
    def worker(gpu_id, n_samples_worker):
        device = f"cuda:{gpu_id}"
        return impute_missing_data(data, missing_mask, model_folder, n_samples_worker, device)
    
    # å¹¶è¡Œæ‰§è¡Œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(gpu_ids)) as executor:
        futures = []
        for gpu_id in gpu_ids:
            future = executor.submit(worker, gpu_id, samples_per_gpu)
            futures.append(future)
        
        results = [future.result() for future in concurrent.futures.as_completed(futures)]
    
    # åˆå¹¶ç»“æœï¼ˆå–å¹³å‡ï¼‰
    final_result = np.mean(results, axis=0)
    return final_result

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
if __name__ == "__main__":
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"ğŸš€ å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°CUDA GPU")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    seq_len, n_features = 200, 20  # âœ… å¢å¤§æµ‹è¯•æ•°æ®
    t = np.linspace(0, 4*np.pi, seq_len)
    data = np.zeros((seq_len, n_features))
    
    for i in range(n_features):
        data[:, i] = np.sin(t + i) + 0.1 * np.random.randn(seq_len)
    
    # éšæœºæ·»åŠ 30%çš„ç¼ºå¤±å€¼
    missing_ratio = 0.3
    missing_indices = np.random.choice(data.size, size=int(missing_ratio * data.size), replace=False)
    data_with_missing = data.copy()
    data_with_missing.flat[missing_indices] = np.nan
    
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
    print(f"ç¼ºå¤±å€¼æ•°é‡: {np.isnan(data_with_missing).sum()}")
    print(f"ç¼ºå¤±æ¯”ä¾‹: {np.isnan(data_with_missing).sum() / data.size:.2%}")
    
    # âœ… GPUåŠ é€Ÿæµ‹è¯•
    try:
        import time
        start_time = time.time()
        
        if torch.cuda.is_available():
            # ä½¿ç”¨GPU
            imputed_data = impute_missing_data(
                data_with_missing, 
                n_samples=30, 
                device="cuda:0"  # æŒ‡å®šä½¿ç”¨GPU 0
            )
        else:
            # å›é€€åˆ°CPU
            imputed_data = impute_missing_data(
                data_with_missing, 
                n_samples=30, 
                device="cpu"
            )
        
        elapsed_time = time.time() - start_time
        
        print(f"å¡«è¡¥åå½¢çŠ¶: {imputed_data.shape}")
        print(f"å¡«è¡¥åç¼ºå¤±å€¼: {np.isnan(imputed_data).sum()}")
        print(f"å¤„ç†æ—¶é—´: {elapsed_time:.2f}ç§’")
        
        # è®¡ç®—å¡«è¡¥ç²¾åº¦
        mse = np.mean((data - imputed_data) ** 2)
        print(f"å¡«è¡¥MSE: {mse:.4f}")
        print("âœ… GPUåŠ é€Ÿå¡«è¡¥æˆåŠŸ!")
        
    except Exception as e:
        print(f"âŒ å¡«è¡¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()